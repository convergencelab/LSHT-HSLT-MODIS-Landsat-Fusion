{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG-19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYjA0FOBzgbDMmedn3p4dN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/convergencelab/LSHT-HSLT-MODIS-Landsat-Fusion/blob/master/VGG_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haWbb8TBPNLN",
        "colab_type": "text"
      },
      "source": [
        "The SR-GAN uses the 2nd layer of the VGG-19 to include feature detection\n",
        "in the perceptual loss function.\n",
        "--rather than using a model pretrained on image net, it may be more useful to use a pre-trained model, trained on\n",
        "  data more similar to that of the scenes we are using for landsat-modis super resolution\n",
        "\n",
        "  -> idea 1) train a binary classifier to differentiate landsat from modis: this does not really achieve the goal\n",
        "  of deriving meaningful features from the image. The major difference between landsat and modis is the resolution\n",
        "  so this sort of classifier would likely produce a model that distinguishes high res from low res.\n",
        "  -> idea 2) explore different landcover/other feature classification approaches on both landsat and modis images:\n",
        "          a) train both and then average weights\n",
        "          b) scale up modis and train on same model ( may cause too much variance between scenes )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGfIB7x6NF4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import tensorflow_datasets as tfds\n",
        "_CITATION = \"\"\"\n",
        "    @misc{helber2017eurosat,\n",
        "    title={EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification},\n",
        "    author={Patrick Helber and Benjamin Bischke and Andreas Dengel and Damian Borth},\n",
        "    year={2017},\n",
        "    eprint={1709.00029},\n",
        "    archivePrefix={arXiv},\n",
        "    primaryClass={cs.CV}\n",
        "}\"\"\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJwtmqeiTuxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Hyperparameters ###\n",
        "batch_size = 5\n",
        "EPOCHS = 1000"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OV6JvgKPZ2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### get data ###\n",
        "\"\"\"\n",
        "using eurosat dataset, this dataset uses the sentenial-2 collected satellite images\n",
        "\"\"\"\n",
        "# load train\n",
        "data, info = tfds.load('eurosat', split=\"train\", with_info=True)\n",
        "\n",
        "\n",
        "ds_size = info.splits[\"train\"].num_examples\n",
        "num_features = info.features[\"label\"].num_classes\n",
        "train_data = data.batch(batch_size).repeat(EPOCHS)\n",
        "train_data = tfds.as_numpy(train_data)\n",
        "\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTijQ6rwPu9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "### initialize model ###\n",
        "vgg = tf.keras.applications.VGG19(\n",
        "                            include_top=True,\n",
        "                            weights=None,\n",
        "                            input_tensor=None,\n",
        "                            input_shape=[224, 224, 3],\n",
        "                            pooling=None,\n",
        "                            classes=1000,\n",
        "                            classifier_activation=\"softmax\"\n",
        "                        )\n",
        "\n",
        "### loss function ###\n",
        "\"\"\"\n",
        "Use MSE loss:\n",
        "  \n",
        "    ref -> \"https://towardsdatascience.com/loss-functions-based-on-feature-activation-and-style-loss-2f0b72fd32a9\"\n",
        "\"\"\"\n",
        "\n",
        "m_loss = tf.keras.losses.MSE\n",
        "\n",
        "### adam optimizer for SGD ###\n",
        "optimizer = tf.keras.optimizers.Adam()\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d88WNQtJP3Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### intialize metrics ###\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_vgg-19_acc')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_vgg-19_acc')\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWHUrLJQTVND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### train step ###\n",
        "@tf.function\n",
        "def train_step(sample, label):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # preprocess for vgg-19\n",
        "    sample = tf.image.resize(sample, (224, 224))\n",
        "    sample = tf.keras.applications.vgg19.preprocess_input(sample)\n",
        "\n",
        "    predictions = vgg(sample, training=True)\n",
        "    # mean squared error in prediction\n",
        "    loss = tf.keras.losses.MSE(label, predictions)\n",
        "\n",
        "  # apply gradients\n",
        "  gradients = tape.gradient(loss, vgg.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, vgg.trainable_variables))\n",
        "\n",
        "  # update metrics\n",
        "  train_loss(loss)\n",
        "  train_accuracy(y_pred=predictions, y_true=label)\n",
        "\n",
        "### generator test step ###\n",
        "@tf.function\n",
        "def test_step(idx, sample, label):\n",
        "  # preprocess for vgg-19\n",
        "  sample = tf.image.resize(sample, (224, 224))\n",
        "  sample = tf.keras.applications.vgg19.preprocess_input(sample)\n",
        "  # feed test sample in\n",
        "  predictions = vgg.predict(sample, training=False)\n",
        "  t_loss = tf.keras.losses.MSE(label, predictions)\n",
        "\n",
        "  # update metrics\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(label, predictions)\n",
        "\n",
        "### Weights Dir ###\n",
        "if not os.path.isdir('./checkpoints'):\n",
        "    os.mkdir('./checkpoints')\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jee-N5B6TZ4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6640c92d-94fc-47e4-ac5c-1f83e5ed46ce"
      },
      "source": [
        "### TRAIN ###\n",
        "NUM_CHECKPOINTS_DIV = int(EPOCHS/4)\n",
        "save_c = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "    ds_size\n",
        "    # train step\n",
        "    for idx in tqdm(range(ds_size // batch_size)):\n",
        "        batch = next(train_data)\n",
        "      \n",
        "        for image, label in zip(batch['image'], batch['label']):\n",
        "          image = np.array(image)[np.newaxis, ...]\n",
        "          label = np.array(label)[np.newaxis, ...]\n",
        "          train_step(image, label)\n",
        "\n",
        "        # test step\n",
        "        # for sample, label in zip(batch[0], batch[1]):\n",
        "         #   sample = np.array(sample)[np.newaxis, ...]\n",
        "         #   label = np.array(label)[np.newaxis, ...]\n",
        "\n",
        "         #   test_step(idx, sample, label)\n",
        "    \n",
        "    ### save weights ###\n",
        "    if not epoch % NUM_CHECKPOINTS_DIV:\n",
        "        vgg.save_weights('./checkpoints/my_checkpoint_{}'.format(save_c))\n",
        "        save_c += 1\n",
        "    if not epoch % 100:\n",
        "        ### outputs every 100 epochs so .out file from slurm is not huge. ###\n",
        "        template = 'Training VGG-19:\\nEpoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "        print(template.format(epoch + 1,\n",
        "                              train_loss.result(),\n",
        "                              train_accuracy.result() * 100,\n",
        "                              test_loss.result(),\n",
        "                              test_accuracy.result() * 100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 7/5400 [01:40<21:32:58, 14.39s/it]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}