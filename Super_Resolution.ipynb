{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Super Resolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fw5gEGaeQ9GVwZMp3IUu9PutQ1q5PL8m",
      "authorship_tag": "ABX9TyOWqSmGu+HoPKQMMpWnrFzW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/convergencelab/LSHT-HSLT-MODIS-Landsat-Fusion/blob/master/Super_Resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj8jQccPIdUq",
        "colab_type": "text"
      },
      "source": [
        "This project will look at taking landsat-MODIS pairs geographically allgined and preprocessed to the same dimensions. Cloud cover content remains below 10%. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpyP3XjHJUFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### imports ###\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import shutil\n",
        "import random\n",
        "import functools\n",
        "import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd0DSANSOQYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Utilities for managing eurosat dataset ###\n",
        "\n",
        "\n",
        "class data_manipulator:\n",
        "    \"\"\"\n",
        "    data manipulator: takes dir with class name/imgs format and splits into\n",
        "    train/test sets\n",
        "    \"\"\"\n",
        "    def __init__(self, base_dir):\n",
        "        self._base_dir = base_dir\n",
        "\n",
        "    def train_test_split(self, validation=False, data_split=0.80):\n",
        "        classes = os.listdir(self._base_dir)\n",
        "        train_dir = self._base_dir + \"/train_data\"\n",
        "        test_dir = self._base_dir + \"/test_data\"\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "        if validation:\n",
        "            os.mkdir(self._base_dir + \"/validation_data\")\n",
        "        for c in classes:\n",
        "            train_class_dir = train_dir+\"/\"+c\n",
        "            test_class_dir = test_dir + \"/\" + c\n",
        "            os.mkdir(train_class_dir)\n",
        "            os.mkdir(test_class_dir)\n",
        "            if not validation:\n",
        "                c_path = self._base_dir + \"/\" + c\n",
        "                c_dir = os.listdir(c_path)\n",
        "                #shuffle images so we take random ones each time for split\n",
        "                random.shuffle(c_dir)\n",
        "                print(c_dir)\n",
        "                train = c_dir[0:int(data_split*len(c_dir))]\n",
        "                test = c_dir[int(data_split*len(c_dir)):]\n",
        "                #move all train data to train folder\n",
        "                for train_data in train:\n",
        "                    shutil.copy(c_path+ \"/\" + train_data, train_class_dir)\n",
        "                # move all test data to test folder\n",
        "                for test_data in test:\n",
        "                    shutil.copy(c_path+ \"/\" + test_data, test_class_dir)\n",
        "            \"\"\"TODO: add validation\"\"\"\n",
        "        print(classes)\n",
        "\n",
        "def split_data(basedir, data_split=0.80):\n",
        "    \"\"\"\n",
        "    quicker for calls in py console\n",
        "    \"\"\"\n",
        "    manip = data_manipulator(basedir)\n",
        "    manip.train_test_split(data_split=data_split)\n",
        "\n",
        "def show_batch(image_batch):\n",
        "    \"\"\"\n",
        "    visualization of batch\n",
        "    :param image_batch: from ds_train typically\n",
        "    :param label_batch: from ds_train typically\n",
        "    :return: None`\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(4, 3, figsize=(12,8))\n",
        "    for n, b in enumerate(image_batch[0]):\n",
        "\n",
        "        ax[n%4, n%3].imshow(b.numpy()\n",
        "                            )\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE0DKhhYIwKJ",
        "colab_type": "text"
      },
      "source": [
        "# Train VGG-19 on Senteniel-2 dataset: EuroSat\n",
        "VGG-19 is used in the architecture proposed in https://arxiv.org/abs/1609.04802:\n",
        "  In novel perceptual loss function, content loss aspect transferred from pretrained VGG-19 using ImageNet dataset. For this project a Remotely sensed dataset may provide more useful features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvFUqBGQJbc5",
        "colab_type": "text"
      },
      "source": [
        "**Step 1: Load in dataset**\n",
        "The EuroSat dataset consists of 10 classes with in total 27,000 labeled and geo-referenced images. For this project we will train the VGG-19 deep convolutional net using this dataset, as it is likely to learn characteristics more similar to that of Landsat and MODIS.\n",
        "\n",
        "ref: https://arxiv.org/pdf/1709.00029.pdf\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LRYsuNbIQUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "class loader(object):\n",
        "    def __init__(self, base_dir, img_width=64, img_height=64):\n",
        "        self._base_dir = pathlib.Path(base_dir)\n",
        "        # toggling custom or all classes selection\n",
        "        self._class_names = np.array([c.name for c in self._base_dir.glob('*')])\n",
        "        #self._labels_as_bool = labels_as_bool\n",
        "        self._image_count = len(list(self._base_dir.glob('*/*.jpg')))\n",
        "        #batch_size as class feature is clunky\n",
        "        #self._batch_size = batch_size\n",
        "        #setting image width and height set here\n",
        "        self._img_width = img_width\n",
        "        self._img_height = img_height\n",
        "        self._ds_size = 0\n",
        "\n",
        "        # load 2 idx can be used to convert output to label\n",
        "        self._current_class_load_idx_2_list = {}\n",
        "        # current data set loaded in loader\n",
        "        self._current_ds = {}\n",
        "\n",
        "\n",
        "\n",
        "    def load_data(self, selected_classes=False, label_as_idx=True):\n",
        "        \"\"\"\n",
        "        load data into memory\n",
        "        :param dirs: if all, use every class in dir, else use selected files\n",
        "        :return: None (void, loads data into loader object)\n",
        "        \"\"\"\n",
        "        #self._ds = tf.data.Dataset.list_files(str(self._base_dir / '*/*'))\n",
        "        if isinstance(selected_classes, list):\n",
        "            to_load = selected_classes\n",
        "        else:\n",
        "            to_load = self._class_names\n",
        "        \"\"\"\n",
        "        idx name to conversion\n",
        "        \"\"\"\n",
        "        if label_as_idx:\n",
        "            self._current_class_load_idx_2_list = {c: float(i) for i, c in enumerate(to_load)}\n",
        "        else:\n",
        "            # convert to bool\n",
        "            self._current_class_load_idx_2_list = {c: c == self._class_names for c in to_load}\n",
        "        \"\"\"\n",
        "        potentially block out to function\n",
        "        \"\"\"\n",
        "        for c in to_load:\n",
        "            # class files indexed using dict\n",
        "            # dict: key is class label as index, val is shuffleDataset of list dir\n",
        "            self._current_ds[self._current_class_load_idx_2_list[c]] = \\\n",
        "                tf.data.Dataset.list_files(str((self._base_dir/c/'*')))\n",
        "            #print(str((self._base_dir / c / '*/*')))\n",
        "        \"\"\"\n",
        "        convert loaded dirs to image tensors\n",
        "        \"\"\"\n",
        "        self._process()\n",
        "\n",
        "\n",
        "    def _decode_img(self, img):\n",
        "        \"\"\"\n",
        "        take tf string and convert to img tensor\n",
        "        :param img:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        img = tf.image.decode_jpeg(img, channels=3)\n",
        "        # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "        # resize the image to the desired size.\n",
        "        return tf.image.resize(img, [self._img_width, self._img_height])\n",
        "\n",
        "    def _map_img(self, class_idx, img_file_path):\n",
        "        \"\"\"\n",
        "        map image function\n",
        "        :param class_idx:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # iterate one class at a time\n",
        "        label = tf.constant(np.array(class_idx).astype('float32').reshape((1)))\n",
        "        # load file\n",
        "        img = tf.io.read_file(img_file_path)\n",
        "        # string tensor is converted to tf.image\n",
        "        img = self._decode_img(img)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "\n",
        "    def _process(self):\n",
        "        \"\"\"\n",
        "        process the files into image, label tensors\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        # intialize with first class\n",
        "        keys = iter(self._current_ds.keys())\n",
        "        init_idx = next(keys)\n",
        "        this_map_func = functools.partial(self._map_img, class_idx=init_idx)\n",
        "        _concat_ds = self._current_ds[init_idx].map(lambda x: this_map_func(img_file_path=x),\n",
        "                                                    num_parallel_calls=AUTOTUNE)\n",
        "        # iter through rest of keys\n",
        "        for cur_class_idx in keys:\n",
        "            this_map_func = functools.partial(self._map_img, class_idx=cur_class_idx)\n",
        "            #convert from dir, and class, to img and class tensors\n",
        "            _concat_ds = _concat_ds.concatenate(self._current_ds[cur_class_idx].map(lambda x: this_map_func(img_file_path=x),\n",
        "                                                                        num_parallel_calls=AUTOTUNE))\n",
        "        # assign concatonated ds to current_ds\n",
        "        self._current_ds = _concat_ds\n",
        "        # get size of ds to set to\n",
        "        self._ds_size = tf.data.experimental.cardinality(self._current_ds).numpy()\n",
        "\n",
        "    def get_ds_size(self):\n",
        "        \"\"\"\n",
        "        currently train is entire dataset\n",
        "        :return: size of training dataset\n",
        "        \"\"\"\n",
        "        \"TODO:\"\n",
        "        return self._ds_size\n",
        "\n",
        "    def reset_load(self):\n",
        "        \"\"\"\n",
        "        resets loaded data set and converter\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        ### reset ###\n",
        "        self._current_class_load_idx_2_list = {}\n",
        "        self._current_ds = {}\n",
        "\n",
        "    def get_dataset(self):\n",
        "        return self._current_ds\n",
        "\n",
        "\n",
        "class training_data_loader(loader):\n",
        "\n",
        "    def __init__(self, base_dir):\n",
        "        super().__init__(base_dir)\n",
        "\n",
        "    def prepare_for_training(self, batch_size=25, cache=True, shuffle_buffer_size=1000):\n",
        "        \"\"\"\n",
        "        prepares dataset for training makes use of caching to speed up transfer\n",
        "        cache is used so we only need to load the ds once and after that it will\n",
        "        refer to cached data rather than reloading multiple instances into mem\n",
        "        :param cache: bool toggle\n",
        "        :param shuffle_buffer_size:\n",
        "        :param batch_size: batch_size for prepared dataset\n",
        "        :return: returns prepared ds\n",
        "        \"\"\"\n",
        "        self._current_ds = self._current_ds.take(batch_size)\n",
        "        if cache:\n",
        "            if isinstance(cache, str):\n",
        "                # if we pass a string to cache\n",
        "                self._current_ds = self._current_ds.cache(cache)\n",
        "            else:\n",
        "                # filename not provided, stored in memory\n",
        "                self._current_ds = self._current_ds.cache()\n",
        "        # fills a buffer with buffer_size els\n",
        "        # randomly samples els from this buffer\n",
        "        self._current_ds = self._current_ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "        # Repeat forever (indefinately) -> this duplicates the data N times\n",
        "        self._current_ds = self._current_ds.repeat()\n",
        "\n",
        "        # Seperates ds into batches of batch size, remainder is not dropped\n",
        "        # may be a batch which has less els than others\n",
        "        # N % D els in last batch\n",
        "        self._current_ds = self._current_ds.batch(batch_size)\n",
        "\n",
        "        # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "        # is training.\n",
        "        self._current_ds = iter(self._current_ds.prefetch(buffer_size=AUTOTUNE))\n",
        "\n",
        "    def get_train_batch(self):\n",
        "        return next(self._current_ds)\n",
        "\n",
        "class testing_data_loader(loader):\n",
        "    def __init__(self, base_dir):\n",
        "        super().__init__(base_dir)\n",
        "\n",
        "    def prepare_for_testing(self, cache=True, shuffle_buffer_size=1000):\n",
        "        \"\"\"\n",
        "        prepares dataset for training makes use of caching to speed up transfer\n",
        "        cache is used so we only need to load the ds once and after that it will\n",
        "        refer to cached data rather than reloading multiple instances into mem\n",
        "        :param cache: bool toggle\n",
        "        :param shuffle_buffer_size:\n",
        "        :param batch_size: batch_size for prepared dataset\n",
        "        :return: returns prepared ds\n",
        "        \"\"\"\n",
        "        if cache:\n",
        "            if isinstance(cache, str):\n",
        "                # if we pass a string to cache\n",
        "                self._current_ds = self._current_ds.cache(cache)\n",
        "            else:\n",
        "                # filename not provided, stored in memory\n",
        "                self._current_ds = self._current_ds.cache()\n",
        "        # fills a buffer with buffer_size els\n",
        "        # randomly samples els from this buffer\n",
        "        self._current_ds = self._current_ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "        # Repeat forever (indefinately) -> this duplicates the data N times\n",
        "        self._current_ds = self._current_ds.repeat()\n",
        "\n",
        "        # Seperates ds into batches of batch size, remainder is not dropped\n",
        "        # may be a batch which has less els than others\n",
        "        # N % D els in last batch\n",
        "\n",
        "\n",
        "        # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "        # is training.\n",
        "        self._current_ds = self._current_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "    def get_test_batch(self, batch_size):\n",
        "        self._current_ds = iter(self._current_ds.batch(batch_size))\n",
        "        return next(self._current_ds)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzISYMyrQinm",
        "colab_type": "text"
      },
      "source": [
        "**Load the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3pIjgBaQTQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "ec6be5dc-f79a-4516-8b17-001f4773343c"
      },
      "source": [
        "### get data ###\n",
        "\"\"\"\n",
        "using eurosat dataset, this dataset uses the sentenial-2 collected satellite images\n",
        "\"\"\"\n",
        "euro_path = r\"C:\\Users\\Noah Barrett\\Desktop\\School\\Research 2020\\data\\EuroSat\"\n",
        "\n",
        "### Hyperparameters ###\n",
        "batch_size = 1\n",
        "\n",
        "### initalize loaders ###\n",
        "train_data = training_data_loader(\n",
        "    base_dir=os.path.join(euro_path, \"train_data\"))\n",
        "test_data = testing_data_loader(\n",
        "    base_dir=os.path.join(euro_path, \"test_data\"))\n",
        "### load data ###\n",
        "train_data.load_data()\n",
        "test_data.load_data()\n",
        "\n",
        "### prep train-data ###\n",
        "train_data.prepare_for_training(batch_size=batch_size)\n",
        "test_data.prepare_for_testing()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3c485f4e4491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     base_dir=os.path.join(euro_path, \"test_data\"))\n\u001b[1;32m     15\u001b[0m \u001b[0;31m### load data ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8133250cd2cb>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, selected_classes, label_as_idx)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mconvert\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mdirs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8133250cd2cb>\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# intialize with first class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0minit_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mthis_map_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         _concat_ds = self._current_ds[init_idx].map(lambda x: this_map_func(img_file_path=x),\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txVp4K4MSFdS",
        "colab_type": "text"
      },
      "source": [
        "**Model Initialization, HyperParameters, and Training**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFyhruF7SEtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "124dc37b-5077-4929-b115-d58b6a1c69cc"
      },
      "source": [
        "### initialize model ###\n",
        "vgg = tf.keras.applications.VGG19(\n",
        "                            include_top=True,\n",
        "                            weights=None,\n",
        "                            input_tensor=None,\n",
        "                            input_shape=[224, 224, 3],\n",
        "                            pooling=None,\n",
        "                            classes=1000,\n",
        "                            classifier_activation=\"softmax\"\n",
        "                        )\n",
        "\n",
        "### loss function ###\n",
        "\"\"\"\n",
        "Use MSE loss:\n",
        "  \n",
        "    ref -> \"https://towardsdatascience.com/loss-functions-based-on-feature-activation-and-style-loss-2f0b72fd32a9\"\n",
        "\"\"\"\n",
        "\n",
        "m_loss = tf.keras.losses.MSE\n",
        "\n",
        "### adam optimizer for SGD ###\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "### intialize metrics ###\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_vgg-19_acc')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_vgg-19_acc')\n",
        "\n",
        "\n",
        "### train step ###\n",
        "@tf.function\n",
        "def train_step(idx, sample, label):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # preprocess for vgg-19\n",
        "    sample = tf.image.resize(sample, (224, 224))\n",
        "    sample = tf.keras.applications.vgg19.preprocess_input(sample)\n",
        "\n",
        "    predictions = vgg(sample, training=True)\n",
        "    # mean squared error in prediction\n",
        "    loss = tf.keras.losses.MSE(label, predictions)\n",
        "\n",
        "  # apply gradients\n",
        "  gradients = tape.gradient(loss, vgg.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, vgg.trainable_variables))\n",
        "\n",
        "  # update metrics\n",
        "  train_loss(loss)\n",
        "  train_accuracy(vgg, predictions)\n",
        "\n",
        "### generator test step ###\n",
        "@tf.function\n",
        "def test_step(idx, sample, label):\n",
        "  # preprocess for vgg-19\n",
        "  sample = tf.image.resize(sample, (224, 224))\n",
        "  sample = tf.keras.applications.vgg19.preprocess_input(sample)\n",
        "  # feed test sample in\n",
        "  predictions = vgg(sample, training=False)\n",
        "  t_loss = tf.keras.losses.MSE(label, predictions)\n",
        "\n",
        "  # update metrics\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(label, predictions)\n",
        "\n",
        "### Weights Dir ###\n",
        "if not os.path.isdir('./checkpoints'):\n",
        "    os.mkdir('./checkpoints')\n",
        "\n",
        "### TRAIN ###\n",
        "EPOCHS = 1000\n",
        "NUM_CHECKPOINTS_DIV = int(EPOCHS/4)\n",
        "save_c = 1\n",
        "### use CPU locally due to OOM error ###\n",
        "with tf.device('/CPU:0'):\n",
        "    for epoch in range(EPOCHS):\n",
        "        # Reset the metrics at the start of the next epoch\n",
        "        train_loss.reset_states()\n",
        "        train_accuracy.reset_states()\n",
        "        test_loss.reset_states()\n",
        "        test_accuracy.reset_states()\n",
        "        for idx in tqdm(range(train_data.get_ds_size() // batch_size)):\n",
        "            # train step\n",
        "            batch = train_data.get_train_batch()\n",
        "            for sample, label in zip(batch[0], batch[1]):\n",
        "                sample = np.array(sample)[np.newaxis, ...]\n",
        "                label = np.array(label)[np.newaxis, ...]\n",
        "                train_step(idx, sample, label)\n",
        "\n",
        "            # test step\n",
        "            batch = test_data.get_test_batch()\n",
        "            for sample, label in zip(batch[0], batch[1]):\n",
        "                sample = np.array(sample)[np.newaxis, ...]\n",
        "                label = np.array(label)[np.newaxis, ...]\n",
        "\n",
        "                test_step(idx, sample, label)\n",
        "\n",
        "        ### save weights ###\n",
        "        if not epoch % NUM_CHECKPOINTS_DIV:\n",
        "            vgg.save_weights('./checkpoints/my_checkpoint_{}'.format(save_c))\n",
        "            save_c += 1\n",
        "        if not epoch % 100:\n",
        "            ### outputs every 100 epochs so .out file from slurm is not huge. ###\n",
        "            template = 'Training VGG-19:\\nEpoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "            print(template.format(epoch + 1,\n",
        "                                  train_loss.result(),\n",
        "                                  train_accuracy.result() * 100,\n",
        "                                  test_loss.result(),\n",
        "                                  test_accuracy.result() * 100))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6bc5b6d5ffd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ds_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;31m# train step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxxgsDswNx94",
        "colab_type": "text"
      },
      "source": [
        "Differences between Landsat, MODIS and Senteniel-2:\n",
        "\n",
        "**Landsat**: \n",
        "*Landsat 8 carries the OLI and TIRS sensors (this project focusses on OLI collected data*\n",
        "\n",
        "*   Scene size: 170 km x 185 km (106 mi x 115 mi))\n",
        "*   233 orbit cycle; covers the entire globe every 16 days (except for the highest polar latitudes)\n",
        "*   Circles the Earth every 98.9 minutes\n",
        "\n",
        "\n",
        "**MODIS**:\n",
        "*The MOD09GA Version 6 product provides an estimate of the surface spectral reflectance of Terra Moderate Resolution Imaging Spectroradiometer (MODIS) Bands 1 through 7, corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. *\n",
        "\n",
        "*   500 meter (m) surface reflectance, observation, and quality bands are a set of ten 1 kilometer (km) observation bands and geolocation flags.\n",
        "\n",
        "refs:\n",
        "    \n",
        "\n",
        "*   https://eos.com/landsat-8/\n",
        "*   https://lpdaac.usgs.gov/products/mod09gav006/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgbSFXkpQRP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_CITATION = \"\"\"\n",
        "    @misc{helber2017eurosat,\n",
        "    title={EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification},\n",
        "    author={Patrick Helber and Benjamin Bischke and Andreas Dengel and Damian Borth},\n",
        "    year={2017},\n",
        "    eprint={1709.00029},\n",
        "    archivePrefix={arXiv},\n",
        "    primaryClass={cs.CV}\n",
        "}\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}